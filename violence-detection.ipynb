{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":397693,"sourceType":"datasetVersion","datasetId":176381}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport pandas as pd\nfrom torch.utils.data import Dataset\nimport numpy as np\nimport cv2\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:11:55.488417Z","iopub.execute_input":"2025-01-09T08:11:55.488751Z","iopub.status.idle":"2025-01-09T08:12:09.743127Z","shell.execute_reply.started":"2025-01-09T08:11:55.488722Z","shell.execute_reply":"2025-01-09T08:12:09.742461Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def create_video_list(base_path):\n    data = []\n    for label, category in enumerate([\"NonViolence\", \"Violence\"]):\n        folder = os.path.join(base_path, category)\n        for video_file in os.listdir(folder):\n            if video_file.endswith((\".mp4\", \".avi\", \".mov\")):  # Add other formats if needed\n                video_path = os.path.join(folder, video_file)\n                data.append((video_path, label))\n    return data\n\n# Example usage\nbase_path = \"/kaggle/input/real-life-violence-situations-dataset/Real Life Violence Dataset\"\nvideo_data = create_video_list(base_path)\nprint(f\"Total videos: {len(video_data)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:09.744843Z","iopub.execute_input":"2025-01-09T08:12:09.745676Z","iopub.status.idle":"2025-01-09T08:12:09.858285Z","shell.execute_reply.started":"2025-01-09T08:12:09.745635Z","shell.execute_reply":"2025-01-09T08:12:09.857496Z"}},"outputs":[{"name":"stdout","text":"Total videos: 2000\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"video_data[:3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:09.859320Z","iopub.execute_input":"2025-01-09T08:12:09.859573Z","iopub.status.idle":"2025-01-09T08:12:09.865495Z","shell.execute_reply.started":"2025-01-09T08:12:09.859549Z","shell.execute_reply":"2025-01-09T08:12:09.864653Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[('/kaggle/input/real-life-violence-situations-dataset/Real Life Violence Dataset/NonViolence/NV_759.mp4',\n  0),\n ('/kaggle/input/real-life-violence-situations-dataset/Real Life Violence Dataset/NonViolence/NV_564.mp4',\n  0),\n ('/kaggle/input/real-life-violence-situations-dataset/Real Life Violence Dataset/NonViolence/NV_126.mp4',\n  0)]"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df = pd.DataFrame(video_data,columns=[\"video_path\",\"target\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:09.867360Z","iopub.execute_input":"2025-01-09T08:12:09.867632Z","iopub.status.idle":"2025-01-09T08:12:09.876142Z","shell.execute_reply.started":"2025-01-09T08:12:09.867606Z","shell.execute_reply":"2025-01-09T08:12:09.875414Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:09.877072Z","iopub.execute_input":"2025-01-09T08:12:09.877368Z","iopub.status.idle":"2025-01-09T08:12:09.898095Z","shell.execute_reply.started":"2025-01-09T08:12:09.877318Z","shell.execute_reply":"2025-01-09T08:12:09.897327Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                             video_path  target\n0     /kaggle/input/real-life-violence-situations-da...       0\n1     /kaggle/input/real-life-violence-situations-da...       0\n2     /kaggle/input/real-life-violence-situations-da...       0\n3     /kaggle/input/real-life-violence-situations-da...       0\n4     /kaggle/input/real-life-violence-situations-da...       0\n...                                                 ...     ...\n1995  /kaggle/input/real-life-violence-situations-da...       1\n1996  /kaggle/input/real-life-violence-situations-da...       1\n1997  /kaggle/input/real-life-violence-situations-da...       1\n1998  /kaggle/input/real-life-violence-situations-da...       1\n1999  /kaggle/input/real-life-violence-situations-da...       1\n\n[2000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_path</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df['target'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:09.898959Z","iopub.execute_input":"2025-01-09T08:12:09.899161Z","iopub.status.idle":"2025-01-09T08:12:09.911183Z","shell.execute_reply.started":"2025-01-09T08:12:09.899141Z","shell.execute_reply":"2025-01-09T08:12:09.910287Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"target\n0    1000\n1    1000\nName: count, dtype: int64"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import cv2\nimport pandas as pd\n\n# Function to get total frames and duration of the video\ndef get_video_info(video_path):\n    # Open the video using OpenCV\n    video = cv2.VideoCapture(video_path)\n    \n    # Get the number of frames in the video\n    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n    \n    # Get the frame rate (frames per second)\n    fps = video.get(cv2.CAP_PROP_FPS)\n    \n    # Calculate the total time of the video in seconds\n    total_time = total_frames / fps if fps != 0 else 0\n    \n    # Release the video capture object\n    video.release()\n    \n    return total_frames, total_time\n\n# Function to apply on the DataFrame\ndef add_video_info(df):\n    # Initialize lists to store the total frames and time for each video\n    total_frames = []\n    total_time = []\n    \n    # Loop through each row in the DataFrame\n    for index, row in df.iterrows():\n        video_path = row['video_path']  # Assuming 'video_path' is the column containing the path\n        frames, time = get_video_info(video_path)\n        \n        total_frames.append(frames)\n        total_time.append(time)\n    \n    # Add the new columns to the DataFrame\n    df['total_frames'] = total_frames\n    df['total_time'] = total_time\n    \n    return df\n\n# Example usage:\n# Assuming you have a DataFrame `df` with a 'video_path' column\n# df = pd.DataFrame({'video_path': ['path_to_video1.mp4', 'path_to_video2.mp4']})\n\n# Apply the function to the DataFrame to add total frames and time\ndf = add_video_info(df)\n\n# Print the updated DataFrame\nprint(df[['video_path', 'total_frames', 'total_time']])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:09.912177Z","iopub.execute_input":"2025-01-09T08:12:09.912434Z","iopub.status.idle":"2025-01-09T08:12:39.695922Z","shell.execute_reply.started":"2025-01-09T08:12:09.912411Z","shell.execute_reply":"2025-01-09T08:12:39.695070Z"}},"outputs":[{"name":"stdout","text":"                                             video_path  total_frames  \\\n0     /kaggle/input/real-life-violence-situations-da...           125   \n1     /kaggle/input/real-life-violence-situations-da...           125   \n2     /kaggle/input/real-life-violence-situations-da...           150   \n3     /kaggle/input/real-life-violence-situations-da...           105   \n4     /kaggle/input/real-life-violence-situations-da...            55   \n...                                                 ...           ...   \n1995  /kaggle/input/real-life-violence-situations-da...           156   \n1996  /kaggle/input/real-life-violence-situations-da...           150   \n1997  /kaggle/input/real-life-violence-situations-da...           177   \n1998  /kaggle/input/real-life-violence-situations-da...           123   \n1999  /kaggle/input/real-life-violence-situations-da...           138   \n\n      total_time  \n0         5.0000  \n1         5.0000  \n2         5.0000  \n3         5.0000  \n4         5.0000  \n...          ...  \n1995      5.2000  \n1996      5.0000  \n1997      5.9000  \n1998      4.1041  \n1999      4.6000  \n\n[2000 rows x 3 columns]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:39.697335Z","iopub.execute_input":"2025-01-09T08:12:39.697708Z","iopub.status.idle":"2025-01-09T08:12:39.707587Z","shell.execute_reply.started":"2025-01-09T08:12:39.697670Z","shell.execute_reply":"2025-01-09T08:12:39.706680Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                             video_path  target  total_frames  \\\n0     /kaggle/input/real-life-violence-situations-da...       0           125   \n1     /kaggle/input/real-life-violence-situations-da...       0           125   \n2     /kaggle/input/real-life-violence-situations-da...       0           150   \n3     /kaggle/input/real-life-violence-situations-da...       0           105   \n4     /kaggle/input/real-life-violence-situations-da...       0            55   \n...                                                 ...     ...           ...   \n1995  /kaggle/input/real-life-violence-situations-da...       1           156   \n1996  /kaggle/input/real-life-violence-situations-da...       1           150   \n1997  /kaggle/input/real-life-violence-situations-da...       1           177   \n1998  /kaggle/input/real-life-violence-situations-da...       1           123   \n1999  /kaggle/input/real-life-violence-situations-da...       1           138   \n\n      total_time  \n0         5.0000  \n1         5.0000  \n2         5.0000  \n3         5.0000  \n4         5.0000  \n...          ...  \n1995      5.2000  \n1996      5.0000  \n1997      5.9000  \n1998      4.1041  \n1999      4.6000  \n\n[2000 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_path</th>\n      <th>target</th>\n      <th>total_frames</th>\n      <th>total_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>125</td>\n      <td>5.0000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>125</td>\n      <td>5.0000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>150</td>\n      <td>5.0000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>105</td>\n      <td>5.0000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>55</td>\n      <td>5.0000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>156</td>\n      <td>5.2000</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>150</td>\n      <td>5.0000</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>177</td>\n      <td>5.9000</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>123</td>\n      <td>4.1041</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>138</td>\n      <td>4.6000</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:39.708658Z","iopub.execute_input":"2025-01-09T08:12:39.708933Z","iopub.status.idle":"2025-01-09T08:12:39.781374Z","shell.execute_reply.started":"2025-01-09T08:12:39.708909Z","shell.execute_reply":"2025-01-09T08:12:39.780639Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"            target  total_frames   total_time\ncount  2000.000000   2000.000000  2000.000000\nmean      0.500000    143.684500     5.252813\nstd       0.500125    290.743559     9.645422\nmin       0.000000     29.000000     1.000000\n25%       0.000000    120.000000     4.880142\n50%       0.500000    132.000000     5.000000\n75%       1.000000    150.000000     5.000000\nmax       1.000000  11272.000000   375.733333","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>total_frames</th>\n      <th>total_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.500000</td>\n      <td>143.684500</td>\n      <td>5.252813</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.500125</td>\n      <td>290.743559</td>\n      <td>9.645422</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>29.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>120.000000</td>\n      <td>4.880142</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.500000</td>\n      <td>132.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>150.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>11272.000000</td>\n      <td>375.733333</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\n\n# Function to detect outliers in the 'total_frames' column using IQR method\ndef detect_outliers(df):\n    # Extract the 'total_frames' column from the DataFrame\n    frame_counts = df['total_frames']\n    \n    # Calculate Q1 (25th percentile) and Q3 (75th percentile)\n    Q1 = frame_counts.quantile(0.25)\n    Q3 = frame_counts.quantile(0.75)\n    \n    # Calculate the IQR\n    IQR = Q3 - Q1\n    \n    # Define the lower and upper bounds for outliers\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    \n    # Find the outliers\n    outliers = df[(frame_counts < lower_bound) | (frame_counts > upper_bound)]\n    \n    return outliers, lower_bound, upper_bound\n\n# Example usage:\n# Assuming your DataFrame `df` has a 'total_frames' column\noutliers, lower_bound, upper_bound = detect_outliers(df)\n\n# Display the outliers and bounds\n# print(\"Outliers detected:\")\n# print(outliers)\n# print(f\"Lower Bound: {lower_bound}\")\n# print(f\"Upper Bound: {upper_bound}\")\noutliers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:39.783725Z","iopub.execute_input":"2025-01-09T08:12:39.784016Z","iopub.status.idle":"2025-01-09T08:12:39.798575Z","shell.execute_reply.started":"2025-01-09T08:12:39.783992Z","shell.execute_reply":"2025-01-09T08:12:39.797563Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                             video_path  target  total_frames  \\\n4     /kaggle/input/real-life-violence-situations-da...       0            55   \n17    /kaggle/input/real-life-violence-situations-da...       0            55   \n35    /kaggle/input/real-life-violence-situations-da...       0            55   \n64    /kaggle/input/real-life-violence-situations-da...       0            55   \n86    /kaggle/input/real-life-violence-situations-da...       0            55   \n...                                                 ...     ...           ...   \n1501  /kaggle/input/real-life-violence-situations-da...       1         11272   \n1578  /kaggle/input/real-life-violence-situations-da...       1           222   \n1669  /kaggle/input/real-life-violence-situations-da...       1           228   \n1718  /kaggle/input/real-life-violence-situations-da...       1          4109   \n1727  /kaggle/input/real-life-violence-situations-da...       1            70   \n\n      total_time  \n4       5.000000  \n17      5.000000  \n35      5.000000  \n64      5.000000  \n86      5.000000  \n...          ...  \n1501  375.733333  \n1578    7.407400  \n1669    7.607600  \n1718  136.966667  \n1727    4.202078  \n\n[115 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_path</th>\n      <th>target</th>\n      <th>total_frames</th>\n      <th>total_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>55</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>55</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>55</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>55</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>55</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1501</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>11272</td>\n      <td>375.733333</td>\n    </tr>\n    <tr>\n      <th>1578</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>222</td>\n      <td>7.407400</td>\n    </tr>\n    <tr>\n      <th>1669</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>228</td>\n      <td>7.607600</td>\n    </tr>\n    <tr>\n      <th>1718</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>4109</td>\n      <td>136.966667</td>\n    </tr>\n    <tr>\n      <th>1727</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>70</td>\n      <td>4.202078</td>\n    </tr>\n  </tbody>\n</table>\n<p>115 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":" outliers.sort_values(by='total_frames', ascending=False)[:20]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:39.799506Z","iopub.execute_input":"2025-01-09T08:12:39.799736Z","iopub.status.idle":"2025-01-09T08:12:39.809932Z","shell.execute_reply.started":"2025-01-09T08:12:39.799713Z","shell.execute_reply":"2025-01-09T08:12:39.809029Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                             video_path  target  total_frames  \\\n1501  /kaggle/input/real-life-violence-situations-da...       1         11272   \n988   /kaggle/input/real-life-violence-situations-da...       0          5397   \n1718  /kaggle/input/real-life-violence-situations-da...       1          4109   \n1409  /kaggle/input/real-life-violence-situations-da...       1           283   \n1669  /kaggle/input/real-life-violence-situations-da...       1           228   \n1578  /kaggle/input/real-life-violence-situations-da...       1           222   \n1330  /kaggle/input/real-life-violence-situations-da...       1           222   \n1442  /kaggle/input/real-life-violence-situations-da...       1           213   \n1484  /kaggle/input/real-life-violence-situations-da...       1           210   \n1438  /kaggle/input/real-life-violence-situations-da...       1           210   \n713   /kaggle/input/real-life-violence-situations-da...       0           204   \n1469  /kaggle/input/real-life-violence-situations-da...       1           201   \n548   /kaggle/input/real-life-violence-situations-da...       0           201   \n509   /kaggle/input/real-life-violence-situations-da...       0           198   \n1420  /kaggle/input/real-life-violence-situations-da...       1            74   \n596   /kaggle/input/real-life-violence-situations-da...       0            73   \n1727  /kaggle/input/real-life-violence-situations-da...       1            70   \n318   /kaggle/input/real-life-violence-situations-da...       0            70   \n917   /kaggle/input/real-life-violence-situations-da...       0            66   \n830   /kaggle/input/real-life-violence-situations-da...       0            63   \n\n      total_time  \n1501  375.733333  \n988   179.900000  \n1718  136.966667  \n1409   11.320000  \n1669    7.607600  \n1578    7.407400  \n1330    7.407400  \n1442    7.100000  \n1484    7.007000  \n1438    7.000000  \n713     6.806800  \n1469    6.706700  \n548     6.700000  \n509     6.606600  \n1420    3.700000  \n596     3.771722  \n1727    4.202078  \n318     2.760000  \n917     2.650556  \n830     3.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_path</th>\n      <th>target</th>\n      <th>total_frames</th>\n      <th>total_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1501</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>11272</td>\n      <td>375.733333</td>\n    </tr>\n    <tr>\n      <th>988</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>5397</td>\n      <td>179.900000</td>\n    </tr>\n    <tr>\n      <th>1718</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>4109</td>\n      <td>136.966667</td>\n    </tr>\n    <tr>\n      <th>1409</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>283</td>\n      <td>11.320000</td>\n    </tr>\n    <tr>\n      <th>1669</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>228</td>\n      <td>7.607600</td>\n    </tr>\n    <tr>\n      <th>1578</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>222</td>\n      <td>7.407400</td>\n    </tr>\n    <tr>\n      <th>1330</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>222</td>\n      <td>7.407400</td>\n    </tr>\n    <tr>\n      <th>1442</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>213</td>\n      <td>7.100000</td>\n    </tr>\n    <tr>\n      <th>1484</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>210</td>\n      <td>7.007000</td>\n    </tr>\n    <tr>\n      <th>1438</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>210</td>\n      <td>7.000000</td>\n    </tr>\n    <tr>\n      <th>713</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>204</td>\n      <td>6.806800</td>\n    </tr>\n    <tr>\n      <th>1469</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>201</td>\n      <td>6.706700</td>\n    </tr>\n    <tr>\n      <th>548</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>201</td>\n      <td>6.700000</td>\n    </tr>\n    <tr>\n      <th>509</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>198</td>\n      <td>6.606600</td>\n    </tr>\n    <tr>\n      <th>1420</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>74</td>\n      <td>3.700000</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>73</td>\n      <td>3.771722</td>\n    </tr>\n    <tr>\n      <th>1727</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>70</td>\n      <td>4.202078</td>\n    </tr>\n    <tr>\n      <th>318</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>70</td>\n      <td>2.760000</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>66</td>\n      <td>2.650556</td>\n    </tr>\n    <tr>\n      <th>830</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>63</td>\n      <td>3.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"upper_bound,lower_bound","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:39.810988Z","iopub.execute_input":"2025-01-09T08:12:39.811334Z","iopub.status.idle":"2025-01-09T08:12:39.817592Z","shell.execute_reply.started":"2025-01-09T08:12:39.811304Z","shell.execute_reply":"2025-01-09T08:12:39.816783Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(195.0, 75.0)"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"import numpy as np\n\n# Function to calculate variance of total frames\ndef calculate_frame_variance(df):\n    # Assuming 'total_frames' column exists after calling add_video_info function\n    frame_counts = df['total_frames']\n    \n    # Calculate the variance of total frames\n    frame_variance = np.var(frame_counts)\n    \n    return frame_variance\n\nframe_variance = calculate_frame_variance(df)\n\nprint(f\"Variance of frames: {frame_variance}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:39.818603Z","iopub.execute_input":"2025-01-09T08:12:39.818882Z","iopub.status.idle":"2025-01-09T08:12:39.826114Z","shell.execute_reply.started":"2025-01-09T08:12:39.818856Z","shell.execute_reply":"2025-01-09T08:12:39.825427Z"}},"outputs":[{"name":"stdout","text":"Variance of frames: 84489.55095975\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Function to plot histogram with custom bins and no log scaling\ndef plot_frame_histogram(df):\n    # Extract the total frames from the DataFrame\n    frame_counts = df['total_frames']\n    \n    # Define a custom number of bins, which is suitable for the range of frame counts\n    bins = 20  # Adjust this based on your dataset, can try other values too\n    \n    # Plot the histogram\n    plt.figure(figsize=(10, 6))\n    plt.hist(frame_counts, bins=bins, color='blue', edgecolor='black', alpha=0.7)\n    \n    # Adding title and labels\n    plt.title('Histogram of Video Frame Counts')\n    plt.xlabel('Total Frames')\n    plt.ylabel('Frequency')\n    \n    # Display grid lines and show the plot\n    plt.grid(True)\n    plt.show()\n\n# Example usage:\n# Assuming your DataFrame `df` has a 'total_frames' column\nplot_frame_histogram(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:39.826852Z","iopub.execute_input":"2025-01-09T08:12:39.827050Z","iopub.status.idle":"2025-01-09T08:12:40.060055Z","shell.execute_reply.started":"2025-01-09T08:12:39.827030Z","shell.execute_reply":"2025-01-09T08:12:40.059195Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Function to plot box plot of total frames\ndef plot_frame_boxplot(df):\n    # Extract the total frames from the DataFrame\n    frame_counts = df['total_frames']\n    \n    # Plot the box plot\n    plt.figure(figsize=(8, 6))\n    plt.boxplot(frame_counts, vert=False, patch_artist=True, \n                boxprops=dict(facecolor='lightblue', color='black'),\n                whiskerprops=dict(color='black'),\n                capprops=dict(color='black'),\n                flierprops=dict(markerfacecolor='red', marker='o', markersize=8))\n    \n    # Adding title and labels\n    plt.title('Box Plot of Video Frame Counts')\n    plt.xlabel('Total Frames')\n    plt.grid(True)\n    plt.show()\n\n# Example usage:\n# Assuming your DataFrame `df` has a 'total_frames' column\nplot_frame_boxplot(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:40.061096Z","iopub.execute_input":"2025-01-09T08:12:40.061436Z","iopub.status.idle":"2025-01-09T08:12:40.248083Z","shell.execute_reply.started":"2025-01-09T08:12:40.061401Z","shell.execute_reply":"2025-01-09T08:12:40.247295Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAApIAAAIjCAYAAACwHvu2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3QElEQVR4nO3de3zO9cPH8fe184YdmJllzHmSMiNJRT9KDnMIld/EpDsVSUl3Ug6lUKnkVqn7Do9yqPnlmBwjkU5YzqdfDkUsh9nYnLbP/Yd2/Vy2YR877/V8PPZg3+/3uq7P9f1cu7x8r+v6zmGMMQIAAAByya2wBwAAAIDiiZAEAACAFUISAAAAVghJAAAAWCEkAQAAYIWQBAAAgBVCEgAAAFYISQAAAFghJAEAAGCFkARKqX379snhcGjq1KmFPRQXixcvVsOGDeXj4yOHw6GkpKTrvs6pU6fK4XBo3759V902IiJCcXFx132bAFAaEJLAdcqMlEu/QkJCdPfdd+vrr78u8PGsWrXKZSyenp6qUaOGevXqpd9++y1PbuP777/XyJEj8yTyLnXs2DE98MAD8vX11aRJk/Tpp5+qTJkyWbbr2LGj/Pz8lJKSkuN1xcbGysvLS8eOHcvTMeaXuLi4LI+jzK/FixcX9vDy1KpVq3T//fcrNDRUXl5eCgkJUUxMjL788svCHpokKTU1VSNHjtSqVasKeyhAkedR2AMASopXXnlF1atXlzFGR44c0dSpU9WuXTstWLBAHTp0KPDxDBw4UE2aNNH58+e1YcMGffTRR/rqq6+0efNmhYWFXdd1f//99xo1apTi4uIUGBiYNwOW9PPPPyslJUWvvvqqWrduneN2sbGxWrBggebMmaNevXplWZ+amqp58+bpvvvuU4UKFfTwww/roYcekre3d56NNT94e3vrf//3f7Msv+WWWwphNPljxIgReuWVV1S7dm3169dP1apV07Fjx7Ro0SJ17dpV06dP1z//+c9CHWNqaqpGjRolSWrZsmWhjgUo6ghJII+0bdtWjRs3dn7ft29fVapUSTNnziyUkLzzzjvVrVs3SVKfPn1Up04dDRw4UNOmTdPQoUMLfDzXIjExUZKuGqcdO3ZUuXLlNGPGjGxDct68eTp9+rRiY2MlSe7u7nJ3d8/z8eY1Dw8P9ezZ85q3P336dLZHbIuq2bNn65VXXlG3bt00Y8YMeXp6OtcNGTJES5Ys0fnz5wtxhAByi5e2gXwSGBgoX19feXi4/n/t9OnTGjx4sMLDw+Xt7a26devqrbfekjFGkpSWlqbIyEhFRkYqLS3Nebnjx4+rcuXKuv3225Wenp7r8fzjH/+QJO3du/eK233zzTe68847VaZMGQUGBqpTp07avn27c/3IkSM1ZMgQSVL16tWdL79e7f2H8fHxio6Olq+vr4KDg9WzZ08dPHjQub5ly5bq3bu3JKlJkyZyOBw5vlfR19dX999/v1asWOGMz0vNmDFD5cqVU8eOHSVl/x5JY4xGjx6tKlWqyM/PT3fffbe2bt2a7e0lJSVp0KBBzjmrVauWxo0bp4yMDJftrja312PkyJFyOBzatm2b/vnPfyooKEh33HGHJGnTpk2Ki4tTjRo15OPjo9DQUD3yyCNZXtbPvI5du3apZ8+eCggIUMWKFfXyyy/LGKPff/9dnTp1kr+/v0JDQzV+/Pgs4zh79qxGjBihWrVqydvbW+Hh4Xr++ed19uzZq96Hl19+WeXLl9cnn3ziEpGZ2rRp4/KfrsTEROd/yHx8fHTLLbdo2rRpLpfJfCvH5S9DZ/ce4Li4OJUtW1YHDx5U586dVbZsWVWsWFHPPfec82dq3759qlixoiRp1KhRzsf3yJEjJUmHDx9Wnz59VKVKFXl7e6ty5crq1KnTNb3/FiiJOCIJ5JGTJ0/q6NGjMsYoMTFREydO1KlTp1yOMBlj1LFjR61cuVJ9+/ZVw4YNtWTJEg0ZMkQHDx7UO++8I19fX02bNk3NmzfXsGHD9Pbbb0uS+vfvr5MnT2rq1KlWR9f+/e9/S5IqVKiQ4zbLly9X27ZtVaNGDY0cOVJpaWmaOHGimjdvrg0bNigiIkL333+/du3apZkzZ+qdd95RcHCwJDn/8c3O1KlT1adPHzVp0kRjxozRkSNHNGHCBK1du1YbN25UYGCghg0bprp16+qjjz5yvk2gZs2aOV5nbGyspk2bpi+++EIDBgxwLj9+/LiWLFmiHj16yNfXN8fLDx8+XKNHj1a7du3Url07bdiwQffee6/OnTvnsl1qaqpatGihgwcPql+/fqpataq+//57DR06VH/++afeffddSdc2t9fi6NGjLt97enoqICDA+X337t1Vu3Ztvf76685AXbZsmX777Tf16dNHoaGh2rp1qz766CNt3bpVP/zwgxwOh8t1Pvjgg6pXr57Gjh2rr776SqNHj1b58uU1efJk/eMf/9C4ceM0ffp0Pffcc2rSpInuuusuSVJGRoY6duyoNWvW6LHHHlO9evW0efNmvfPOO9q1a5fmzp2b4/3avXu3duzYoUceeUTlypW76n5IS0tTy5YttWfPHg0YMEDVq1dXfHy84uLilJSUpKeffvqa9ufl0tPT1aZNGzVt2lRvvfWWli9frvHjx6tmzZp64oknVLFiRX3wwQd64okn1KVLF91///2SpJtvvlmS1LVrV23dulVPPfWUIiIilJiYqGXLlunAgQOKiIiwGhNQrBkA12XKlClGUpYvb29vM3XqVJdt586daySZ0aNHuyzv1q2bcTgcZs+ePc5lQ4cONW5ubmb16tUmPj7eSDLvvvvuVcezcuVKI8l88skn5q+//jKHDh0yX331lYmIiDAOh8P8/PPPxhhj9u7daySZKVOmOC/bsGFDExISYo4dO+Zc9uuvvxo3NzfTq1cv57I333zTSDJ79+696njOnTtnQkJCzE033WTS0tKcyxcuXGgkmeHDhzuXZe7LzDFeyYULF0zlypVNs2bNXJZ/+OGHRpJZsmRJluvNHG9iYqLx8vIy7du3NxkZGc7tXnzxRSPJ9O7d27ns1VdfNWXKlDG7du1yuZ0XXnjBuLu7mwMHDhhjcje32endu3e2j6MWLVoYY4wZMWKEkWR69OiR5bKpqalZls2cOdNIMqtXr3Yuy7yOxx57zLnswoULpkqVKsbhcJixY8c6l584ccL4+vq67ItPP/3UuLm5me+++87ltjL3+dq1a3O8f/PmzTOSzDvvvHPF/ZDp3XffNZLMZ5995lx27tw506xZM1O2bFmTnJxsjPnP433lypUul8/u8Z25j1955RWXbaOiokx0dLTz+7/++stIMiNGjHDZ7sSJE0aSefPNN6/pPgClAS9tA3lk0qRJWrZsmZYtW6bPPvtMd999tx599FGXT6IuWrRI7u7uGjhwoMtlBw8eLGOMy6e8R44cqfr166t379568skn1aJFiyyXu5JHHnlEFStWVFhYmNq3b6/Tp09r2rRpLu/jvNSff/6phIQExcXFqXz58s7lN998s+655x4tWrTomm/7Ur/88osSExP15JNPysfHx7m8ffv2ioyM1FdffWV1ve7u7nrooYe0bt06l5cVZ8yYoUqVKqlVq1Y5Xnb58uU6d+6cnnrqKZejdYMGDcqybXx8vO68804FBQXp6NGjzq/WrVsrPT1dq1evlpS7uc2Jj4+P8zGU+XX5y8uPP/54lstdeuT1zJkzOnr0qG677TZJ0oYNG7Js/+ijjzr/7u7ursaNG8sYo759+zqXBwYGqm7dui6f9I+Pj1e9evUUGRnpsi8y3zaxcuXKHO9bcnKyJF3T0Ujp4v4MDQ1Vjx49nMs8PT01cOBAnTp1St9+++01XU92Lt+Hd9555zWd0cDX11deXl5atWqVTpw4YX37QEnCS9tAHrn11ltdIq1Hjx6KiorSgAED1KFDB3l5eWn//v0KCwvL8o9pvXr1JEn79+93LvPy8tInn3yiJk2ayMfHR1OmTMnyEuWVDB8+XHfeeafc3d0VHBysevXqZXm/5qUyb7tu3bpZ1tWrV09Lliyx+nDHla43MjJSa9asydX1XSo2NlbvvPOOZsyYoRdffFF//PGHvvvuOw0cOPCKL/9njql27douyytWrKigoCCXZbt379amTZtyfOk+8z2auZnbnLi7u1/x0+rSxfelXu748eMaNWqUZs2aleU9oydPnsyyfdWqVV2+DwgIkI+Pj/NtCpcuv/R9lrt379b27duvui+y4+/vL0lXPGXTpfbv36/atWvLzc31eEdu9md2fHx8sow/KCjomsLQ29tb48aN0+DBg1WpUiXddttt6tChg3r16qXQ0FCr8QDFHSEJ5BM3NzfdfffdmjBhgnbv3q369evn+jqWLFki6eJRpt27d2cbETlp0KDBVaOkuIuOjlZkZKRmzpypF198UTNnzpQxxvlp7byQkZGhe+65R88//3y26+vUqZNnt3Utsnvf5wMPPKDvv/9eQ4YMUcOGDVW2bFllZGTovvvuy/KBIEnZRnZO4W0u+aBQRkaGGjRo4Hzf7uXCw8NzHHdkZKQkafPmzTluYyOn/1zl9IG06/30/qBBgxQTE6O5c+dqyZIlevnllzVmzBh98803ioqKuq7rBoojQhLIRxcuXJAknTp1SpJUrVo1LV++XCkpKS5Hrnbs2OFcn2nTpk165ZVX1KdPHyUkJOjRRx/V5s2bXT54kZcyb3vnzp1Z1u3YsUPBwcHOo5G5OTJ66fVmvgSaaefOnS732UZsbKxefvllbdq0STNmzFDt2rXVpEmTaxrT7t27VaNGDefyv/76K8uRqZo1a+rUqVNXjfLczG1eOnHihFasWKFRo0Zp+PDhzuW7d+/O89uqWbOmfv31V7Vq1SpXjwHpYnDXrVtX8+bN04QJE1S2bNkrbl+tWjVt2rRJGRkZLkclL9+fmUeQLz85vu0RS+nqj++aNWtq8ODBGjx4sHbv3q2GDRtq/Pjx+uyzz6xvEyiueI8kkE/Onz+vpUuXysvLy/lyXLt27ZSenq7/+Z//cdn2nXfekcPhUNu2bZ2XjYuLU1hYmCZMmKCpU6fqyJEjeuaZZ/JtvJUrV1bDhg01bdo0l3+Ut2zZoqVLl6pdu3bOZZlBeS2/2aZx48YKCQnRhx9+6HKKmK+//lrbt29X+/btr2vcmUcfhw8froSEhGs6Gtm6dWt5enpq4sSJLkfcMj+BfakHHnhA69atcx4dvlRSUpLzPwvXOrd5LfMIm7nsFEPZ3Zfr9cADD+jgwYP6+OOPs6xLS0vT6dOnr3j5UaNG6dixY3r00Ued++1SS5cu1cKFCyVd3J+HDx/W559/7lx/4cIFTZw4UWXLllWLFi0kXQxKd3d353tVM73//vu5vn+Z/Pz8JGV9fKempurMmTMuy2rWrKly5cpd0+mPgJKII5JAHvn666+dR0sSExM1Y8YM7d69Wy+88ILz/WExMTG6++67NWzYMO3bt0+33HKLli5dqnnz5mnQoEHO092MHj1aCQkJWrFihcqVK6ebb75Zw4cP10svvaRu3bq5RF1eevPNN9W2bVs1a9ZMffv2dZ7+JyAgwHkePeniS8qSNGzYMD300EPy9PRUTExMtu+f9PT01Lhx49SnTx+1aNFCPXr0cJ7+JyIi4rrjuHr16rr99ts1b948SbqmkMw8d+CYMWPUoUMHtWvXThs3btTXX3+d5X2CQ4YM0fz589WhQwfFxcUpOjpap0+f1ubNmzV79mzt27dPwcHB1zy3ec3f31933XWX3njjDZ0/f1433HCDli5detXzhdp4+OGH9cUXX+jxxx/XypUr1bx5c6Wnp2vHjh364osvtGTJkhw/zCVdPO3Q5s2b9dprr2njxo3q0aOH8zfbLF68WCtWrNCMGTMkSY899pgmT56suLg4rV+/XhEREZo9e7bWrl2rd99913nUNyAgQN27d9fEiRPlcDhUs2ZNLVy48Irv17waX19f3Xjjjfr8889Vp04dlS9fXjfddJMuXLigVq1a6YEHHtCNN94oDw8PzZkzR0eOHNFDDz1kfXtAsVaInxgHSoTsTv/j4+NjGjZsaD744AOX08sYY0xKSop55plnTFhYmPH09DS1a9c2b775pnO79evXGw8PD/PUU0+5XO7ChQumSZMmJiwszJw4cSLH8WSeDiU+Pv6K487u9CjGGLN8+XLTvHlz4+vra/z9/U1MTIzZtm1blsu/+uqr5oYbbjBubm7XdCqgzz//3ERFRRlvb29Tvnx5Exsba/744w+XbXJz+p9LTZo0yUgyt956a7brLz/9jzHGpKenm1GjRpnKlSsbX19f07JlS7NlyxZTrVo1l1PeGHNxzoYOHWpq1aplvLy8THBwsLn99tvNW2+9Zc6dO+ey3ZXm9kp69+5typQpk+P6zFP3/PXXX1nW/fHHH6ZLly4mMDDQBAQEmO7du5tDhw5lOYVNTteR0223aNHC1K9f32XZuXPnzLhx40z9+vWNt7e3CQoKMtHR0WbUqFHm5MmTV72fxhizYsUK06lTJxMSEmI8PDxMxYoVTUxMjJk3b57LdkeOHDF9+vQxwcHBxsvLyzRo0CDL49WYi6fr6dq1q/Hz8zNBQUGmX79+ZsuWLdme/ie7+5m5Xy71/fffm+joaOPl5eXcj0ePHjX9+/c3kZGRpkyZMiYgIMA0bdrUfPHFF9d0v4GSyGFMHvzKBQAAAJQ6vEcSAAAAVghJAAAAWCEkAQAAYIWQBAAAgBVCEgAAAFYISQAAAFgp8BOSZ2Rk6NChQypXrlyuf8UWAAAA8p8xRikpKQoLC3P5NaWXK/CQPHTokMLDwwv6ZgEAAJBLv//+u6pUqZLj+gIPycxfa/X77787f21cfsj8Pcf33nuvPD098+12cO2Yk6KF+ShamI+ihfkoepiTgpWcnKzw8HBnt+WkwEMy8+Vsf3//fA9JPz8/+fv784ArIpiTooX5KFqYj6KF+Sh6mJPCcbW3IfJhGwAAAFghJAEAAGCFkAQAAIAVQhIAAABWCEkAAABYISQBAABghZAEAACAFUISAAAAVghJAAAAWCEkAQAAYIWQBAAAgBVCEgAAAFYISQAAAFghJAEAAGCFkAQAAIAVQhIAAABWCEkAAABYISQBAABghZAEAACAFUISAAAAVghJAAAAWCEkAQAAYIWQBAAAgBVCEgAAAFYISQAAAFghJAEAAGCFkAQAAIAVQhIAAABWCEkAAABYISQBAABghZAEAACAFUISAAAAVghJAAAAWCEkAQAAYIWQBAAAgBVCEgAAAFYISQAAAFghJAEAAGCFkAQAAIAVQhIAAABWCEkAAABYISQBAABghZAEAACAFUISAAAAVghJAAAAWCEkAQAAYIWQBAAAgBVCEgAAAFYISQAAAFghJAEAAGCFkAQAAIAVQhIAAABWCEkAAABYISQBAABghZAEAACAFUISAAAAVghJAAAAWCEkAQAAYIWQBAAAgBVCEgAAAFYISQAAAFghJAEAAGCFkAQAAIAVQhIAAABWCEkAAABYISQBAABghZAEAACAFUISAAAAVghJAAAAWCEkAQAAYIWQBAAAgBVCEgAAAFYISQAAAFghJAEAAGCFkAQAAIAVQhIAAABWCEkAAABYISQBAABghZAEAACAFUISAAAAVghJAAAAWCEkAQAAYIWQBAAAgBVCEgAAAFYISQAAAFghJAEAAGCFkAQAAIAVQhIAAABWCEkAAABYISQBAABghZAEAACAFUISAAAAVghJAAAAWCEkAQAAYIWQBAAAgBVCEgAAAFYISQAAAFghJAEAAGCFkAQAAIAVQhIAAABWCEkAAABYISQBAABghZAEAACAFUISAAAAVghJAAAAWCEkAQAAYIWQBAAAgBVCEgAAAFYISQAAAFghJAEAAGCFkAQAAIAVQhIAAABWCEkAAABYISQBAABghZAEAACAFUISAAAAVghJAAAAWCEkAQAAYIWQBAAAgBVCEgAAAFYISQAAAFghJAEAAGCFkAQAAIAVQhIAAABWCEkAAABYISQBAABghZAEAACAFUISAAAAVghJAAAAWCEkAQAAYIWQBAAAgBVCEgAAAFYISQAAAFghJAEAAGCFkAQAAIAVQhIAAABWCEkAAABYISQBAABghZAEAACAFUISAAAAVghJAAAAWCEkAQAAYIWQBAAAgBVCEgAAAFYISQAAAFghJAEAAGCFkAQAAIAVQhIAAABWCEkAAABYISQBAABghZAEAACAFUISAAAAVghJAAAAWCEkAQAAYIWQBAAAgBVCEgAAAFYISQAAAFghJAEAAGCFkAQAAIAVQhIAAABWCEkAAABYISQBAABghZAEAACAFUISAAAAVghJAAAAWCEkAQAAYIWQBAAAgBVCEgAAAFYISQAAAFghJAEAAGCFkAQAAIAVQhIAAABWCEkAAABYISQBAABghZAEAACAFUISAAAAVghJAAAAWCEkAQAAYIWQBAAAgBVCEgAAAFYISQAAAFghJAEAAGCFkAQAAIAVQhIAAABWCEkAAABYISQBAABghZAEAACAFUISAAAAVghJAAAAWCEkAQAAYIWQBAAAgBVCEgAAAFY8CnsAheH333bq1L6NKhsRpfAadQt7OAAAAMVSqTsieeDAAT3UqpHqre6nh1o10oEDBwp7SAAAAMVSqQvJo0ePKu3MGUlS2pkzOnr0aCGPCAAAoHgqdSEJAACAvEFIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADACiEJAAAAK4QkAAAArBCSAAAAsEJIAgAAwEqpCcnU1FRt2LBBaWlpLsvT0tK0YcMGpaamFtLIAAAAiqdSE5I7duxQdHS09u3b57J83759io6O1o4dOwpnYAAAAMVUqQlJAAAA5C1CEgAAAFYISQAAAFghJAEAAGCFkAQAAIAVQhIAAABWCEkAAABYISQBAABghZAEAACAFUISAAAAVghJAAAAWPEo7AHkl6SkJHXu3NllmZuknj17Kir0P/3cs2dPSVJ0dPTFqnZzU926dRUSHKwKFSuqc+fO6t69u3x8fAps7EBBO3PmjOLj4zV37lwlHTumwAoVSt1jn30AoKgpDs9LJfKI5LBhwxQSEiI3Se5/L7tdUndJzS7ZLrv1TTMytH37dq397jttnzNHvXr1UnhYmBYsWFBg4wcK0oIFCxQeFqZevXopce5cVfz2WyXOnVuqHvvz588v9fsAQNFSXJ6Xch2Sq1evVkxMjMLCwuRwODR37tx8GJa9YcOG6fXXX5ckGUkdJO2UtFbSLEk3XLJtduu///v7tpJ2GKP3JTVPSlLnTp00f/78grobQIH46aef1L1bNzVPStJOSd9lZGjW33/uVOl47M+fP19dOncu1fsAQNFSnJ6Xch2Sp0+f1i233KJJkyblx3iuS1JSkl5//XW5SfKR1FHSvyTV+Xv94b+/zzwK2eKy9ZnqSJqji5H5kqTpxihGUt+4OJ05cyZ/7wRQQM6cOaNJEyYoRtK/jMn25+BfJfyxf+bMGfWNiyvV+wBA0VLcnpdyHZJt27bV6NGj1aVLl/wYz3V54YUXJEkZks5IekP/iUZJ+qcuHoVM//v7py9bfyl3SW9KOq6LUTnOGB09cUKzZ8/O+4EDhWD27Nk6efq03jDmij8HJfmxHx8fr6MnTpTqfQCgaCluz0v5/mGbs2fP6uzZs87vk5OTJUnnz5/X+fPn8/S2Mg/xlpd0o7IeaVwnyVNSwN/fV7vK9dWVdJsuhmRPSc3d3PSvf/1LDz74YF4NuVTJnO+8nnfYmTdvnpo7HKpjzBW3q6uS+9j/8ssvdYebm+pkZFxxu4LYB/x8FC3MR9FTWuakqDwvXet+zveQHDNmjEaNGpVl+dKlS+Xn55ent3X65Em5S/KS63shMxldrHjPXFxnVUlH//77DRkZ2rFnjxYtWnR9Ay3lli1bVthDgKS9//636l0lIjOV1Mf+b3v2qN5VnqwzFdQ+4OejaGE+ip6SPidF5XkpNTX1mrbL95AcOnSonn32Wef3ycnJCg8P17333it/f/88va0yAQFKTk3VOUkHs1nv0MWXtXPzf5kDksL+/vtBNzfVqFVL7dq1u86Rlk7nz5/XsmXLdM8998jTMzc5j/wwZcoU/bF1q3QNMVlSH/tTp07VwW3bpGt40s7vfcDPR9HCfBQ9pWVOisrzUuYryFeT7yHp7e0tb2/vLMs9PT3z/IHQsWNHTZ48WcclrZG0S64vbzeTtFLSyb+/368rv7y9U9IPkj79++9rMzL0adeuJfoBXBDyY+6Re506ddIj8+Zl+Tm5XEl+7N9///3qNXdukdoH/HwULcxH0VPS56SoPC9d63WWqPNIjh07VpKcn9p+Xv/5YI0kzdDFo5KZb16dcNn6S6VLGqKL77fsIum/HQ4FBwWpW7dueT9woBB069ZNAWXK6HmH44o/ByX5sd+9e3cFBwWV6n0AoGgpbs9LuQ7JU6dOKSEhQQkJCZKkvXv3KiEhQQcOHMjrseVaYGCgXnrpJeentudL6qqLRyYlKVQXTzqeOTHfXrY+005djMeFkkZLinU4tEDSJ9OmFZkzyQPXy8fHR/2ffloLJHV1OLL9Oehawh/7Pj4++mTatFK9DwAULcXteSnXIfnLL78oKipKUVFRkqRnn31WUVFRGj58eJ4Pzsarr76qF198UdLFo48LdfGTTbdLelAX3/OYKbv1zSRFSvpaUqTDoSclrQ0M1Nx58xQTE1NQdwMoELfeeqviZ8/W2sBA1ZV0h5ubHvz7z0iVjsd+TEyM5sydW6r3AYCipTg9L+X6PZItW7aUucZPehaW1157TYMGDVJISIhz2TpJP+riOSaj/l6Wof8cncxcLzc31bvkd22/2KWLunXrVujFD+SXmJgYtTt0SLNnz9acOXN09PhxVSpfXp+Wosd+x44d9Xsp3wcAipbi8ryU7x+2KSyBgYGaO3eu2rVrJ09PT23YsEHR0dH67LPPNP65Xs7tPvvsM/Xs2VPr169Xo0aNCnHEQOHx8fFRz5491bNnz8IeSqFhHwAoaorD81KJ+rANAAAACg4hCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADACiEJAAAAKyX2VyReLjIyUuvXr1daWprL8oiICK1fv16RkZGFNDIAAIDiqdQckfTz81OjRo3k6+vrstzX11eNGjWSn59fIY0MAACgeCo1IQkAAIC8RUgCAADACiEJAAAAK4QkAAAArBCSAAAAsEJIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADASqkLyeDgYPn6+EiSfH18FBwcXMgjAgAAKJ48CnsABa1q1aqatWKDtu/bqFm9ohRetWphDwkAAKBYKnUhKUnhNepKNeoW9jAAAACKtVL30jYAAADyBiEJAAAAK4QkAAAArBCSAAAAsEJIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADACiEJAAAAK4QkAAAArBCSAAAAsEJIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADACiEJAAAAK4QkAAAArBCSAAAAsEJIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADACiEJAAAAK4QkAAAArBCSAAAAsEJIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADACiEJAAAAK4QkAAAArBCSAAAAsEJIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADACiEJAAAAK4QkAAAArBCSAAAAsEJIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADACiEJAAAAK4QkAAAArBCSAAAAsEJIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADACiEJAAAAK4QkAAAArBCSAAAAsEJIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADACiEJAAAAK4QkAAAArBCSAAAAsEJIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADACiEJAAAAK4QkAAAArBCSAAAAsEJIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADACiEJAAAAK4QkAAAArBCSAAAAsEJIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADACiEJAAAAK4QkAAAArBCSAAAAsEJIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADACiEJAAAAK4QkAAAArBCSAAAAsEJIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADACiEJAAAAK4QkAAAArBCSAAAAsEJIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADACiEJAAAAK4QkAAAArBCSAAAAsEJIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADACiEJAAAAK4QkAAAArBCSAAAAsEJIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAAACwQkgCAADAikdB36AxRpKUnJycr7dz/vx5paamKjk5WZ6envl6W7g2zEnRwnwULcxH0cJ8FD3MScHK7LTMbstJgYdkSkqKJCk8PLygbxoAAAC5kJKSooCAgBzXO8zVUjOPZWRk6NChQypXrpwcDke+3U5ycrLCw8P1+++/y9/fP99uB9eOOSlamI+ihfkoWpiPooc5KVjGGKWkpCgsLExubjm/E7LAj0i6ubmpSpUqBXZ7/v7+POCKGOakaGE+ihbmo2hhPooe5qTgXOlIZCY+bAMAAAArhCQAAACslNiQ9Pb21ogRI+Tt7V3YQ8HfmJOihfkoWpiPooX5KHqYk6KpwD9sAwAAgJKhxB6RBAAAQP4iJAEAAGCFkAQAAIAVQhIAAABWSmxITpo0SREREfLx8VHTpk31008/FfaQir0xY8aoSZMmKleunEJCQtS5c2ft3LnTZZszZ86of//+qlChgsqWLauuXbvqyJEjLtscOHBA7du3l5+fn0JCQjRkyBBduHDBZZtVq1apUaNG8vb2Vq1atTR16tT8vnvF3tixY+VwODRo0CDnMuaj4B08eFA9e/ZUhQoV5OvrqwYNGuiXX35xrjfGaPjw4apcubJ8fX3VunVr7d692+U6jh8/rtjYWPn7+yswMFB9+/bVqVOnXLbZtGmT7rzzTvn4+Cg8PFxvvPFGgdy/4iQ9PV0vv/yyqlevLl9fX9WsWVOvvvqqy+8OZj7yz+rVqxUTE6OwsDA5HA7NnTvXZX1B7vv4+HhFRkbKx8dHDRo00KJFi/L8/pZapgSaNWuW8fLyMp988onZunWr+a//+i8TGBhojhw5UthDK9batGljpkyZYrZs2WISEhJMu3btTNWqVc2pU6ec2zz++OMmPDzcrFixwvzyyy/mtttuM7fffrtz/YULF8xNN91kWrdubTZu3GgWLVpkgoODzdChQ53b/Pbbb8bPz888++yzZtu2bWbixInG3d3dLF68uEDvb3Hy008/mYiICHPzzTebp59+2rmc+ShYx48fN9WqVTNxcXHmxx9/NL/99ptZsmSJ2bNnj3ObsWPHmoCAADN37lzz66+/mo4dO5rq1aubtLQ05zb33XefueWWW8wPP/xgvvvuO1OrVi3To0cP5/qTJ0+aSpUqmdjYWLNlyxYzc+ZM4+vrayZPnlyg97eoe+2110yFChXMwoULzd69e018fLwpW7asmTBhgnMb5iP/LFq0yAwbNsx8+eWXRpKZM2eOy/qC2vdr16417u7u5o033jDbtm0zL730kvH09DSbN2/O931QGpTIkLz11ltN//79nd+np6ebsLAwM2bMmEIcVcmTmJhoJJlvv/3WGGNMUlKS8fT0NPHx8c5ttm/fbiSZdevWGWMuPrG4ubmZw4cPO7f54IMPjL+/vzl79qwxxpjnn3/e1K9f3+W2HnzwQdOmTZv8vkvFUkpKiqldu7ZZtmyZadGihTMkmY+C99///d/mjjvuyHF9RkaGCQ0NNW+++aZzWVJSkvH29jYzZ840xhizbds2I8n8/PPPzm2+/vpr43A4zMGDB40xxrz//vsmKCjIOUeZt123bt28vkvFWvv27c0jjzzisuz+++83sbGxxhjmoyBdHpIFue8feOAB0759e5fxNG3a1PTr1y9P72NpVeJe2j537pzWr1+v1q1bO5e5ubmpdevWWrduXSGOrOQ5efKkJKl8+fKSpPXr1+v8+fMu+z4yMlJVq1Z17vt169apQYMGqlSpknObNm3aKDk5WVu3bnVuc+l1ZG7D/GWvf//+at++fZZ9xnwUvPnz56tx48bq3r27QkJCFBUVpY8//ti5fu/evTp8+LDL/gwICFDTpk1d5iQwMFCNGzd2btO6dWu5ubnpxx9/dG5z1113ycvLy7lNmzZttHPnTp04cSK/72axcfvtt2vFihXatWuXJOnXX3/VmjVr1LZtW0nMR2EqyH3Pc1j+KnEhefToUaWnp7v8wyhJlSpV0uHDhwtpVCVPRkaGBg0apObNm+umm26SJB0+fFheXl4KDAx02fbSfX/48OFs5yZz3ZW2SU5OVlpaWn7cnWJr1qxZ2rBhg8aMGZNlHfNR8H777Td98MEHql27tpYsWaInnnhCAwcO1LRp0yT9Z59e6fnp8OHDCgkJcVnv4eGh8uXL52reIL3wwgt66KGHFBkZKU9PT0VFRWnQoEGKjY2VxHwUpoLc9zltw9zkDY/CHgCKp/79+2vLli1as2ZNYQ+l1Pr999/19NNPa9myZfLx8Sns4UAX/4PVuHFjvf7665KkqKgobdmyRR9++KF69+5dyKMrfb744gtNnz5dM2bMUP369ZWQkKBBgwYpLCyM+QDySIk7IhkcHCx3d/csn0w9cuSIQkNDC2lUJcuAAQO0cOFCrVy5UlWqVHEuDw0N1blz55SUlOSy/aX7PjQ0NNu5yVx3pW38/f3l6+ub13en2Fq/fr0SExPVqFEjeXh4yMPDQ99++63ee+89eXh4qFKlSsxHAatcubJuvPFGl2X16tXTgQMHJP1nn17p+Sk0NFSJiYku6y9cuKDjx4/nat4gDRkyxHlUskGDBnr44Yf1zDPPOI/gMx+FpyD3fU7bMDd5o8SFpJeXl6Kjo7VixQrnsoyMDK1YsULNmjUrxJEVf8YYDRgwQHPmzNE333yj6tWru6yPjo6Wp6eny77fuXOnDhw44Nz3zZo10+bNm12eHJYtWyZ/f3/nP8DNmjVzuY7MbZg/V61atdLmzZuVkJDg/GrcuLFiY2Odf2c+Clbz5s2znBJr165dqlatmiSpevXqCg0NddmfycnJ+vHHH13mJCkpSevXr3du88033ygjI0NNmzZ1brN69WqdP3/euc2yZctUt25dBQUF5dv9K25SU1Pl5ub6z5y7u7syMjIkMR+FqSD3Pc9h+aywP+2TH2bNmmW8vb3N1KlTzbZt28xjjz1mAgMDXT6Zitx74oknTEBAgFm1apX5888/nV+pqanObR5//HFTtWpV880335hffvnFNGvWzDRr1sy5PvN0M/fee69JSEgwixcvNhUrVsz2dDNDhgwx27dvN5MmTeJ0M9fo0k9tG8N8FLSffvrJeHh4mNdee83s3r3bTJ8+3fj5+ZnPPvvMuc3YsWNNYGCgmTdvntm0aZPp1KlTtqc8iYqKMj/++KNZs2aNqV27tsspT5KSkkylSpXMww8/bLZs2WJmzZpl/Pz8Sv3pZi7Xu3dvc8MNNzhP//Pll1+a4OBg8/zzzzu3YT7yT0pKitm4caPZuHGjkWTefvtts3HjRrN//35jTMHt+7Vr1xoPDw/z1ltvme3bt5sRI0Zw+p88VCJD0hhjJk6caKpWrWq8vLzMrbfean744YfCHlKxJynbrylTpji3SUtLM08++aQJCgoyfn5+pkuXLubPP/90uZ59+/aZtm3bGl9fXxMcHGwGDx5szp8/77LNypUrTcOGDY2Xl5epUaOGy20gZ5eHJPNR8BYsWGBuuukm4+3tbSIjI81HH33ksj4jI8O8/PLLplKlSsbb29u0atXK7Ny502WbY8eOmR49epiyZcsaf39/06dPH5OSkuKyza+//mruuOMO4+3tbW644QYzduzYfL9vxU1ycrJ5+umnTdWqVY2Pj4+pUaOGGTZsmMupYpiP/LNy5cps/83o3bu3MaZg9/0XX3xh6tSpY7y8vEz9+vXNV199lW/3u7RxGHPJKf4BAACAa1Ti3iMJAACAgkFIAgAAwAohCQAAACuEJAAAAKwQkgAAALBCSAIAAMAKIQkAAAArhCQAAACsEJIAcAmHw6G5c+cW9jAAoFggJAEUSQ6H44pfI0eOzPGy+/btk8PhUEJCQp6PKy4uLtvx7NmzJ89vCwCKOo/CHgAAZOfPP/90/v3zzz/X8OHDtXPnTueysmXLFsawJEn33XefpkyZ4rKsYsWKWbY7d+6cvLy8CmpYAFDgOCIJoEgKDQ11fgUEBMjhcDi/DwkJ0dtvv60qVarI29tbDRs21OLFi52XrV69uiQpKipKDodDLVu2lCT9/PPPuueeexQcHKyAgAC1aNFCGzZsyPXYvL29XcYXGhoqd3d3tWzZUgMGDNCgQYMUHBysNm3aSJLefvttNWjQQGXKlFF4eLiefPJJnTp1ynl9U6dOVWBgoBYuXKi6devKz89P3bp1U2pqqqZNm6aIiAgFBQVp4MCBSk9Pd17u7Nmzeu6553TDDTeoTJkyatq0qVatWuVcv3//fsXExCgoKEhlypRR/fr1tWjRolzfXwDICSEJoNiZMGGCxo8fr7feekubNm1SmzZt1LFjR+3evVuS9NNPP0mSli9frj///FNffvmlJCklJUW9e/fWmjVr9MMPP6h27dpq166dUlJS8mxs06ZNk5eXl9auXasPP/xQkuTm5qb33ntPW7du1bRp0/TNN9/o+eefd7lcamqq3nvvPc2aNUuLFy/WqlWr1KVLFy1atEiLFi3Sp59+qsmTJ2v27NnOywwYMEDr1q3TrFmztGnTJnXv3l333Xefcz/0799fZ8+e1erVq7V582aNGzeuUI/kAiiBDAAUcVOmTDEBAQHO78PCwsxrr73msk2TJk3Mk08+aYwxZu/evUaS2bhx4xWvNz093ZQrV84sWLDAuUySmTNnTo6X6d27t3F3dzdlypRxfnXr1s0YY0yLFi1MVFTUVe9PfHy8qVChgsv9k2T27NnjXNavXz/j5+dnUlJSnMvatGlj+vXrZ4wxZv/+/cbd3d0cPHjQ5bpbtWplhg4daowxpkGDBmbkyJFXHQ8A2OI9kgCKleTkZB06dEjNmzd3Wd68eXP9+uuvV7zskSNH9NJLL2nVqlVKTExUenq6UlNTdeDAgVyN4e6779YHH3zg/L5MmTLOv0dHR2fZfvny5RozZox27Nih5ORkXbhwQWfOnFFqaqr8/PwkSX5+fqpZs6bzMpUqVVJERITLEcRKlSopMTFRkrR582alp6erTp06Lrd19uxZVahQQZI0cOBAPfHEE1q6dKlat26trl276uabb87VfQWAKyEkAZQavXv31rFjxzRhwgRVq1ZN3t7eatasmc6dO5er6ylTpoxq1aqV47pL7du3Tx06dNATTzyh1157TeXLl9eaNWvUt29fnTt3zhmSnp6eLpdzOBzZLsvIyJAknTp1Su7u7lq/fr3c3d1dtsuMz0cffVRt2rTRV199paVLl2rMmDEaP368nnrqqVzdXwDICe+RBFCs+Pv7KywsTGvXrnVZvnbtWt14442S5Pyk9KUfTMncZuDAgWrXrp3q168vb29vHT16NF/Hu379emVkZGj8+PG67bbbVKdOHR06dOi6rzcqKkrp6elKTExUrVq1XL5CQ0Od24WHh+vxxx/Xl19+qcGDB+vjjz++7tsGgEwckQRQ7AwZMkQjRoxQzZo11bBhQ02ZMkUJCQmaPn26JCkkJES+vr5avHixqlSpIh8fHwUEBKh27dr69NNP1bhxYyUnJ2vIkCHy9fXN17HWqlVL58+f18SJExUTE+PyIZzrUadOHcXGxqpXr14aP368oqKi9Ndff2nFihW6+eab1b59ew0aNEht27ZVnTp1dOLECa1cuVL16tXLg3sFABdxRBJAsTNw4EA9++yzGjx4sBo0aKDFixdr/vz5ql27tiTJw8ND7733niZPnqywsDB16tRJkvR///d/OnHihBo1aqSHH35YAwcOVEhISL6O9ZZbbtHbb7+tcePG6aabbtL06dM1ZsyYPLnuKVOmqFevXho8eLDq1q2rzp076+eff1bVqlUlXTwi279/f9WrV0/33Xef6tSpo/fffz9PbhsAJMlhjDGFPQgAAAAUPxyRBAAAgBVCEgAAAFYISQAAAFghJAEAAGCFkAQAAIAVQhIAAABWCEkAAABYISQBAABghZAEAACAFUISAAAAVghJAAAAWPl/zNe4BQ/Le0cAAAAASUVORK5CYII="},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"import pandas as pd\nimport cv2\n\n# Function to get video frame size\ndef get_frame_size(video_path):\n    cap = cv2.VideoCapture(video_path)\n    if not cap.isOpened():\n        return None, None  # Handle the case where the video cannot be opened\n    \n    # Get frame width and height\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    \n    cap.release()  # Release the video capture object\n    return width, height\n\n# Apply the function to all videos in the DataFrame\ndf['frame_size'] = df['video_path'].apply(lambda x: get_frame_size(x))\n\n# Split width and height into separate columns\ndf[['frame_width', 'frame_height']] = pd.DataFrame(df['frame_size'].tolist(), index=df.index)\n\n# Drop the frame_size column if not needed\ndf.drop(columns=['frame_size'], inplace=True)\n\n# Print the updated DataFrame\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:40.249085Z","iopub.execute_input":"2025-01-09T08:12:40.249351Z","iopub.status.idle":"2025-01-09T08:12:48.065578Z","shell.execute_reply.started":"2025-01-09T08:12:40.249326Z","shell.execute_reply":"2025-01-09T08:12:48.064764Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                             video_path  target  total_frames  \\\n0     /kaggle/input/real-life-violence-situations-da...       0           125   \n1     /kaggle/input/real-life-violence-situations-da...       0           125   \n2     /kaggle/input/real-life-violence-situations-da...       0           150   \n3     /kaggle/input/real-life-violence-situations-da...       0           105   \n4     /kaggle/input/real-life-violence-situations-da...       0            55   \n...                                                 ...     ...           ...   \n1995  /kaggle/input/real-life-violence-situations-da...       1           156   \n1996  /kaggle/input/real-life-violence-situations-da...       1           150   \n1997  /kaggle/input/real-life-violence-situations-da...       1           177   \n1998  /kaggle/input/real-life-violence-situations-da...       1           123   \n1999  /kaggle/input/real-life-violence-situations-da...       1           138   \n\n      total_time  frame_width  frame_height  \n0         5.0000          224           224  \n1         5.0000          224           224  \n2         5.0000          224           224  \n3         5.0000          224           224  \n4         5.0000          224           224  \n...          ...          ...           ...  \n1995      5.2000          670           692  \n1996      5.0000          728           714  \n1997      5.9000          716           720  \n1998      4.1041          640           360  \n1999      4.6000          728           720  \n\n[2000 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_path</th>\n      <th>target</th>\n      <th>total_frames</th>\n      <th>total_time</th>\n      <th>frame_width</th>\n      <th>frame_height</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>125</td>\n      <td>5.0000</td>\n      <td>224</td>\n      <td>224</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>125</td>\n      <td>5.0000</td>\n      <td>224</td>\n      <td>224</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>150</td>\n      <td>5.0000</td>\n      <td>224</td>\n      <td>224</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>105</td>\n      <td>5.0000</td>\n      <td>224</td>\n      <td>224</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>0</td>\n      <td>55</td>\n      <td>5.0000</td>\n      <td>224</td>\n      <td>224</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>156</td>\n      <td>5.2000</td>\n      <td>670</td>\n      <td>692</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>150</td>\n      <td>5.0000</td>\n      <td>728</td>\n      <td>714</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>177</td>\n      <td>5.9000</td>\n      <td>716</td>\n      <td>720</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>123</td>\n      <td>4.1041</td>\n      <td>640</td>\n      <td>360</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>/kaggle/input/real-life-violence-situations-da...</td>\n      <td>1</td>\n      <td>138</td>\n      <td>4.6000</td>\n      <td>728</td>\n      <td>720</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 6 columns</p>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:48.066947Z","iopub.execute_input":"2025-01-09T08:12:48.067283Z","iopub.status.idle":"2025-01-09T08:12:48.087518Z","shell.execute_reply.started":"2025-01-09T08:12:48.067221Z","shell.execute_reply":"2025-01-09T08:12:48.086719Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"            target  total_frames   total_time  frame_width  frame_height\ncount  2000.000000   2000.000000  2000.000000  2000.000000   2000.000000\nmean      0.500000    143.684500     5.252813   508.389000    399.571000\nstd       0.500125    290.743559     9.645422   407.384241    234.476164\nmin       0.000000     29.000000     1.000000   136.000000    224.000000\n25%       0.000000    120.000000     4.880142   224.000000    224.000000\n50%       0.500000    132.000000     5.000000   224.000000    300.000000\n75%       1.000000    150.000000     5.000000   640.000000    606.500000\nmax       1.000000  11272.000000   375.733333  1920.000000   1920.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>total_frames</th>\n      <th>total_time</th>\n      <th>frame_width</th>\n      <th>frame_height</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n      <td>2000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.500000</td>\n      <td>143.684500</td>\n      <td>5.252813</td>\n      <td>508.389000</td>\n      <td>399.571000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.500125</td>\n      <td>290.743559</td>\n      <td>9.645422</td>\n      <td>407.384241</td>\n      <td>234.476164</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>29.000000</td>\n      <td>1.000000</td>\n      <td>136.000000</td>\n      <td>224.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>120.000000</td>\n      <td>4.880142</td>\n      <td>224.000000</td>\n      <td>224.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.500000</td>\n      <td>132.000000</td>\n      <td>5.000000</td>\n      <td>224.000000</td>\n      <td>300.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>150.000000</td>\n      <td>5.000000</td>\n      <td>640.000000</td>\n      <td>606.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>11272.000000</td>\n      <td>375.733333</td>\n      <td>1920.000000</td>\n      <td>1920.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split into training (70%), validation (20%), and test (10%)\ntrain_df, test_df = train_test_split(df, test_size=0.1, random_state=42, stratify=df['target'])\ntrain_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['target'])\n\nprint(f\"Train: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:48.088575Z","iopub.execute_input":"2025-01-09T08:12:48.088873Z","iopub.status.idle":"2025-01-09T08:12:48.493949Z","shell.execute_reply.started":"2025-01-09T08:12:48.088846Z","shell.execute_reply":"2025-01-09T08:12:48.493043Z"}},"outputs":[{"name":"stdout","text":"Train: 1440, Validation: 360, Test: 200\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"train_df['target'].value_counts(),val_df['target'].value_counts(),test_df['target'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:48.495011Z","iopub.execute_input":"2025-01-09T08:12:48.495590Z","iopub.status.idle":"2025-01-09T08:12:48.503170Z","shell.execute_reply.started":"2025-01-09T08:12:48.495554Z","shell.execute_reply":"2025-01-09T08:12:48.502246Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(target\n 0    720\n 1    720\n Name: count, dtype: int64,\n target\n 1    180\n 0    180\n Name: count, dtype: int64,\n target\n 0    100\n 1    100\n Name: count, dtype: int64)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"import numpy as np\nimport cv2\nfrom tensorflow.keras.utils import Sequence\n\nclass VideoDataGenerator(Sequence):\n    def __init__(self, video_paths, labels, batch_size, max_frames=50, frame_size=(128, 128), frame_interval=3):\n        self.video_paths = video_paths\n        self.labels = labels\n        self.batch_size = batch_size\n        self.max_frames = max_frames\n        self.frame_size = frame_size\n        self.frame_interval = frame_interval  # To pick every 5th frame\n\n    def __len__(self):\n        return int(np.floor(len(self.video_paths) / self.batch_size))\n\n    def __getitem__(self, index):\n        batch_video_paths = self.video_paths[index * self.batch_size: (index + 1) * self.batch_size]\n        batch_labels = self.labels[index * self.batch_size: (index + 1) * self.batch_size]\n\n        videos = []\n        for video_path in batch_video_paths:\n            frames = self.load_video_frames(video_path)\n            frames = self.resize_frames(frames, self.frame_size)\n            frames = self.pad_video_frames(frames, self.max_frames)\n            videos.append(frames)\n\n        return np.array(videos, dtype=np.float32), np.array(batch_labels)\n\n    def load_video_frames(self, video_path):\n        frames = []\n        cap = cv2.VideoCapture(video_path)\n        \n        frame_count = 0\n        while cap.isOpened():\n            ret, frame = cap.read()\n            if not ret:\n                break\n            frame_count += 1\n            \n            # Select every 5th frame\n            if frame_count % self.frame_interval == 0:\n                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n                frames.append(frame)\n        \n        cap.release()\n        return frames\n\n    def resize_frames(self, frames, frame_size):\n        return [cv2.resize(frame, frame_size) for frame in frames]\n\n    def pad_video_frames(self, frames, max_frames):\n        if len(frames) < max_frames:\n            padding = max_frames - len(frames)\n            frames.extend([np.zeros_like(frames[0])] * padding)  # Pad with empty frames\n        else:\n            frames = frames[:max_frames]  # Crop to max_frames\n        return np.array(frames)\n\n\ntrain_gen = VideoDataGenerator(train_df['video_path'], train_df['target'], batch_size=32, frame_interval=3)\nval_gen = VideoDataGenerator(val_df['video_path'], val_df['target'], batch_size=32, frame_interval=3)\ntest_gen = VideoDataGenerator(test_df['video_path'], test_df['target'], batch_size=32, frame_interval=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:48.504320Z","iopub.execute_input":"2025-01-09T08:12:48.504581Z","iopub.status.idle":"2025-01-09T08:12:48.516975Z","shell.execute_reply.started":"2025-01-09T08:12:48.504551Z","shell.execute_reply":"2025-01-09T08:12:48.516265Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# Input Layer\ninputs = layers.Input(shape=(50, 128, 128, 3))  # 50 frames of 128x128 RGB images\n\n# First block of 3D Convolutions\nx = layers.Conv3D(16, kernel_size=(5, 5, 5), activation='relu', padding='same')(inputs)\nx = layers.AveragePooling3D(pool_size=(2, 2, 2))(x)\nx = layers.BatchNormalization()(x)\nx = layers.Dropout(0.2)(x)\n\n# Second block of 3D Convolutions\nx = layers.Conv3D(32, kernel_size=(3, 3, 3), activation='relu', padding='same')(x)\nx = layers.AveragePooling3D(pool_size=(2, 2, 2))(x)\nx = layers.BatchNormalization()(x)\nx = layers.Dropout(0.3)(x)\n\n# TimeDistributed GlobalAveragePooling2D\nx = layers.TimeDistributed(layers.GlobalAveragePooling2D())(x)\n\n# Bidirectional LSTM layer\nx = layers.Bidirectional(layers.LSTM(128))(x)\nx = layers.Dropout(0.5)(x)\n\n# Fully connected layer\nx = layers.Dense(64, activation='relu')(x)\nx = layers.BatchNormalization()(x)\nx = layers.Dropout(0.3)(x)\n\n# Output layer for binary classification\noutputs = layers.Dense(1, activation='sigmoid')(x)\n\n# Create Model\nmodel = models.Model(inputs, outputs)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Print the model summary\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:48.517906Z","iopub.execute_input":"2025-01-09T08:12:48.518146Z","iopub.status.idle":"2025-01-09T08:12:49.889003Z","shell.execute_reply.started":"2025-01-09T08:12:48.518123Z","shell.execute_reply":"2025-01-09T08:12:49.888144Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n│                                 │ \u001b[38;5;34m3\u001b[0m)                     │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv3d (\u001b[38;5;33mConv3D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,   │         \u001b[38;5;34m6,016\u001b[0m │\n│                                 │ \u001b[38;5;34m16\u001b[0m)                    │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling3d               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mAveragePooling3D\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m) │            \u001b[38;5;34m64\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv3d_1 (\u001b[38;5;33mConv3D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m) │        \u001b[38;5;34m13,856\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling3d_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mAveragePooling3D\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m) │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m164,864\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv3d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,016</span> │\n│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                    │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling3d               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling3D</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>) │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv3d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv3D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,856</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling3d_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling3D</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,864</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m201,697\u001b[0m (787.88 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201,697</span> (787.88 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m201,473\u001b[0m (787.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">201,473</span> (787.00 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m224\u001b[0m (896.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> (896.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"checkpoint_callback = ModelCheckpoint(\n    filepath='best_model.keras',           # Path to save the model\n    monitor='val_loss',                 # Metric to monitor (use 'val_accuracy' if you prefer)\n    save_best_only=True,                # Only save the best model\n    save_weights_only=False,            # Save the entire model (set to True to save weights only)\n    mode='min',                         # Save model when val_loss is at its minimum\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:49.890070Z","iopub.execute_input":"2025-01-09T08:12:49.890409Z","iopub.status.idle":"2025-01-09T08:12:49.894795Z","shell.execute_reply.started":"2025-01-09T08:12:49.890381Z","shell.execute_reply":"2025-01-09T08:12:49.893874Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Train the model\nhistory = model.fit(train_gen, validation_data=val_gen, epochs=10, callbacks=[checkpoint_callback])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T08:12:49.895739Z","iopub.execute_input":"2025-01-09T08:12:49.895991Z","iopub.status.idle":"2025-01-09T09:05:35.952159Z","shell.execute_reply.started":"2025-01-09T08:12:49.895967Z","shell.execute_reply":"2025-01-09T09:05:35.951493Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m19/45\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 5s/step - accuracy: 0.5063 - loss: 0.8997","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a046c49ddc0] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a046c49ddc0] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5748 - loss: 0.8105\nEpoch 1: val_loss improved from inf to 0.63363, saving model to best_model.keras\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 6s/step - accuracy: 0.5766 - loss: 0.8080 - val_accuracy: 0.7045 - val_loss: 0.6336\nEpoch 2/10\n\u001b[1m26/45\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:43\u001b[0m 5s/step - accuracy: 0.7427 - loss: 0.5359","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a080c00d640] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a080c00d640] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7533 - loss: 0.5283\nEpoch 2: val_loss improved from 0.63363 to 0.54234, saving model to best_model.keras\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 6s/step - accuracy: 0.7538 - loss: 0.5277 - val_accuracy: 0.7898 - val_loss: 0.5423\nEpoch 3/10\n\u001b[1m18/45\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:01\u001b[0m 5s/step - accuracy: 0.8305 - loss: 0.3878","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a09a7986ac0] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a09a7986ac0] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8199 - loss: 0.4144\nEpoch 3: val_loss did not improve from 0.54234\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 6s/step - accuracy: 0.8195 - loss: 0.4152 - val_accuracy: 0.7102 - val_loss: 0.5649\nEpoch 4/10\n","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a046c006700] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a046c006700] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8382 - loss: 0.3696\nEpoch 4: val_loss improved from 0.54234 to 0.48775, saving model to best_model.keras\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 6s/step - accuracy: 0.8381 - loss: 0.3696 - val_accuracy: 0.7557 - val_loss: 0.4877\nEpoch 5/10\n\u001b[1m 1/45\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25:51\u001b[0m 35s/step - accuracy: 0.9062 - loss: 0.2412","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a08303a93c0] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a08303a93c0] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8286 - loss: 0.3909\nEpoch 5: val_loss did not improve from 0.48775\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 6s/step - accuracy: 0.8288 - loss: 0.3905 - val_accuracy: 0.7699 - val_loss: 0.4884\nEpoch 6/10\n\u001b[1m 6/45\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:18\u001b[0m 10s/step - accuracy: 0.8823 - loss: 0.3003","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a09b81d4180] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a09b81d4180] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8631 - loss: 0.3399\nEpoch 6: val_loss did not improve from 0.48775\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 6s/step - accuracy: 0.8629 - loss: 0.3399 - val_accuracy: 0.5653 - val_loss: 1.4638\nEpoch 7/10\n","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a08000df7c0] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a08000df7c0] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8493 - loss: 0.3520\nEpoch 7: val_loss did not improve from 0.48775\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 6s/step - accuracy: 0.8495 - loss: 0.3515 - val_accuracy: 0.6562 - val_loss: 0.9606\nEpoch 8/10\n\u001b[1m 1/45\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26:01\u001b[0m 35s/step - accuracy: 0.9062 - loss: 0.2328","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a09841d9840] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a09841d9840] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8731 - loss: 0.3054\nEpoch 8: val_loss did not improve from 0.48775\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 6s/step - accuracy: 0.8730 - loss: 0.3055 - val_accuracy: 0.7983 - val_loss: 0.5866\nEpoch 9/10\n\u001b[1m10/45\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:10\u001b[0m 7s/step - accuracy: 0.9003 - loss: 0.2558","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a0464051600] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a0464051600] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8813 - loss: 0.2854\nEpoch 9: val_loss improved from 0.48775 to 0.41290, saving model to best_model.keras\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 6s/step - accuracy: 0.8811 - loss: 0.2856 - val_accuracy: 0.8267 - val_loss: 0.4129\nEpoch 10/10\n\u001b[1m34/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m58s\u001b[0m 5s/step - accuracy: 0.8892 - loss: 0.2800 ","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a082809be80] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a082809be80] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8882 - loss: 0.2793\nEpoch 10: val_loss did not improve from 0.41290\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 6s/step - accuracy: 0.8881 - loss: 0.2793 - val_accuracy: 0.8125 - val_loss: 0.5133\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Train the model\nhistory_1 = model.fit(train_gen, validation_data=val_gen, epochs=5, callbacks=[checkpoint_callback])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T09:05:35.953249Z","iopub.execute_input":"2025-01-09T09:05:35.953530Z","iopub.status.idle":"2025-01-09T09:32:08.964323Z","shell.execute_reply.started":"2025-01-09T09:05:35.953504Z","shell.execute_reply":"2025-01-09T09:32:08.963670Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m 7/45\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:50\u001b[0m 4s/step - accuracy: 0.8903 - loss: 0.2492","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a04601d0f40] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a04601d0f40] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8974 - loss: 0.2464\nEpoch 1: val_loss improved from 0.41290 to 0.32406, saving model to best_model.keras\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 6s/step - accuracy: 0.8974 - loss: 0.2466 - val_accuracy: 0.8892 - val_loss: 0.3241\nEpoch 2/5\n","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a08119caf80] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a08119caf80] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8992 - loss: 0.2407\nEpoch 2: val_loss did not improve from 0.32406\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 6s/step - accuracy: 0.8990 - loss: 0.2411 - val_accuracy: 0.7102 - val_loss: 0.6045\nEpoch 3/5\n\u001b[1m25/45\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:33\u001b[0m 5s/step - accuracy: 0.9042 - loss: 0.2369","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a046c0ab5c0] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a046c0ab5c0] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9036 - loss: 0.2393\nEpoch 3: val_loss did not improve from 0.32406\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 6s/step - accuracy: 0.9036 - loss: 0.2395 - val_accuracy: 0.7415 - val_loss: 0.8939\nEpoch 4/5\n\u001b[1m13/45\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:29\u001b[0m 5s/step - accuracy: 0.9016 - loss: 0.2365","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a07fc1014c0] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a07fc1014c0] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9049 - loss: 0.2308\nEpoch 4: val_loss did not improve from 0.32406\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 6s/step - accuracy: 0.9048 - loss: 0.2311 - val_accuracy: 0.6534 - val_loss: 1.4082\nEpoch 5/5\n\u001b[1m 7/45\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:17\u001b[0m 5s/step - accuracy: 0.8636 - loss: 0.3149","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a0840044400] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a0840044400] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8839 - loss: 0.2696\nEpoch 5: val_loss did not improve from 0.32406\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 6s/step - accuracy: 0.8842 - loss: 0.2691 - val_accuracy: 0.7756 - val_loss: 0.6128\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"history_2 = model.fit(train_gen, validation_data=val_gen, epochs=5, callbacks=[checkpoint_callback])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T09:32:08.965646Z","iopub.execute_input":"2025-01-09T09:32:08.965994Z","iopub.status.idle":"2025-01-09T09:58:07.487770Z","shell.execute_reply.started":"2025-01-09T09:32:08.965955Z","shell.execute_reply":"2025-01-09T09:58:07.487101Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m 5/45\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:26\u001b[0m 5s/step - accuracy: 0.9132 - loss: 0.1670","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a09b810da80] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a09b810da80] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9155 - loss: 0.1999\nEpoch 1: val_loss did not improve from 0.32406\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 6s/step - accuracy: 0.9155 - loss: 0.2004 - val_accuracy: 0.8409 - val_loss: 0.4457\nEpoch 2/5\n\u001b[1m 6/45\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:43\u001b[0m 9s/step - accuracy: 0.9263 - loss: 0.2065 ","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a08003b6e00] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a08003b6e00] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9204 - loss: 0.2034\nEpoch 2: val_loss did not improve from 0.32406\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 6s/step - accuracy: 0.9201 - loss: 0.2039 - val_accuracy: 0.7869 - val_loss: 0.7335\nEpoch 3/5\n\u001b[1m37/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m41s\u001b[0m 5s/step - accuracy: 0.9061 - loss: 0.2139","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a085c17fb40] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a085c17fb40] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9074 - loss: 0.2142\nEpoch 3: val_loss did not improve from 0.32406\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m308s\u001b[0m 6s/step - accuracy: 0.9075 - loss: 0.2143 - val_accuracy: 0.8239 - val_loss: 0.4737\nEpoch 4/5\n\u001b[1m21/45\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2:18\u001b[0m 6s/step - accuracy: 0.9237 - loss: 0.2073","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a047002f300] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a047002f300] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9232 - loss: 0.2095\nEpoch 4: val_loss did not improve from 0.32406\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 6s/step - accuracy: 0.9231 - loss: 0.2097 - val_accuracy: 0.8011 - val_loss: 0.5510\nEpoch 5/5\n\u001b[1m 2/45\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:14\u001b[0m 5s/step - accuracy: 0.9375 - loss: 0.1394  ","output_type":"stream"},{"name":"stderr","text":"[h264 @ 0x7a0838059a00] mb_type 104 in P slice too large at 98 31\n[h264 @ 0x7a0838059a00] error while decoding MB 98 31\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9148 - loss: 0.2007\nEpoch 5: val_loss did not improve from 0.32406\n\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 6s/step - accuracy: 0.9146 - loss: 0.2011 - val_accuracy: 0.8352 - val_loss: 0.4240\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"model.save(\"/kaggle/working/violnce_model.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T09:58:07.489094Z","iopub.execute_input":"2025-01-09T09:58:07.489495Z","iopub.status.idle":"2025-01-09T09:58:07.554830Z","shell.execute_reply.started":"2025-01-09T09:58:07.489456Z","shell.execute_reply":"2025-01-09T09:58:07.554005Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import load_model\n\n# Load the model\nmodel_path = '/kaggle/working/best_model.keras'\nmodel = load_model(model_path)\n\nloss, accuracy = model.evaluate(test_gen)\n\n# Print the test loss and accuracy\nprint(f'Test Loss: {loss}')\nprint(f'Test Accuracy: {accuracy}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T09:58:07.555906Z","iopub.execute_input":"2025-01-09T09:58:07.556160Z","iopub.status.idle":"2025-01-09T09:58:44.166348Z","shell.execute_reply.started":"2025-01-09T09:58:07.556136Z","shell.execute_reply":"2025-01-09T09:58:44.165479Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4s/step - accuracy: 0.8633 - loss: 0.2897\nTest Loss: 0.29301515221595764\nTest Accuracy: 0.859375\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}